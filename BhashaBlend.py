# -*- coding: utf-8 -*-
"""Spanish(NEW).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z4-ohtokN8-qgwWIzjwnjYvCcUWDeFM4
"""

## IMPORTANT DEPENDENCIES TO RUN FIRST
 !pip install git+https://github.com/openai/whisper.git
 !sudo apt update && sudo apt install ffmpeg

!pip install gTTS
from gtts import gTTS

!pip install SpeechRecognition

pip install googletrans==4.0.0-rc1

!pip install bert-score sentence-transformers nltk rouge-score

!pip install pydub

pip install whisper_timestamped

!pip install pydub moviepy
import moviepy.editor as mp
from pydub import AudioSegment
import whisper

def extract_audio_and_video(video_path, audio_output_path, video_output_path_without_audio):
    try:
        video = mp.VideoFileClip(video_path)

        # Save original audio
        audio = video.audio
        audio.write_audiofile(audio_output_path)

        # Save video without audio
        video_without_audio = video.set_audio(None)
        video_without_audio.write_videofile(video_output_path_without_audio, codec='libx264', audio_codec='aac')

        print("Extraction complete.")
    except Exception as e:
        print(f"Error: {e}")

def mp3_to_wav(mp3_path, wav_path):
    try:
        sound = AudioSegment.from_mp3(mp3_path)
        sound.export(wav_path, format="wav")
        print("Conversion complete.")
    except Exception as e:
        print(f"Error: {e}")

def transcribe_audio(audio_file, source_language):
    try:
        print("Transcribing audio track")
        model = whisper.load_model("medium")
        trans = model.transcribe(audio_file, language=source_language, verbose=False)
        # Remove timestamps
        trans_text = " ".join(word['word'] for word in trans)
        return trans_text
    except Exception as e:
        print(f"Error transcribing audio: {e}")
        return None

if __name__ == "__main__":
    video_path = input("Enter the path of the original video: ")
    audio_output_path_mp3 = "output_audio.mp3"
    video_output_path_without_audio = "video_without_audio.mp4"
    audio_output_path_wav = "output_audio.wav"
    source_language = input("Enter the language code of the audio (e.g., en-US for English-US): ")

    # Extract audio and video without audio
    extract_audio_and_video(video_path, audio_output_path_mp3, video_output_path_without_audio)

    # Convert mp3 to wav
    mp3_to_wav(audio_output_path_mp3, audio_output_path_wav)

    # Transcribe audio
    transcribed_text = transcribe_audio(audio_output_path_wav, source_language)
    if transcribed_text:
        print("Transcription:")
        print(transcribed_text)

"""**TRANSCRIPT OF ORIGINAL LANGUAGE**"""

import whisper_timestamped as whisper

audio_path = '/content/output_audio.mp3'  # Updated audio path
transcript_with_timestamps_path = "transcript_with_timestamps.txt"
transcript_without_timestamps_path = "transcript_without_timestamps.txt"

try:
    # Load audio and model
    audio = whisper.load_audio(audio_path)
    model = whisper.load_model("small")

    # Perform transcription with timestamps
    result = whisper.transcribe(model, audio, language="hi")

    # Write transcript with timestamps
    with open(transcript_with_timestamps_path, "w", encoding="utf-8") as txt_file:
        for segment in result['segments']:
            start_time = segment['start']
            end_time = segment['end']
            text = segment['text'].strip()
            txt_file.write(f"{start_time:.2f} --> {end_time:.2f}\n{text}\n")
            print(f"{start_time:.2f} --> {end_time:.2f}\n{text}")

    print("Transcription with timestamps saved to:", transcript_with_timestamps_path)

    # Write transcript without timestamps
    with open(transcript_without_timestamps_path, "w", encoding="utf-8") as txt_file:
        for segment in result['segments']:
            text = segment['text'].strip()
            txt_file.write(text + "\n")
            print(text)

    print("Transcript without timestamps saved to:", transcript_without_timestamps_path)

except Exception as e:
    print(f"Error: {e}")

"""**TRANSLATION CODE**"""

import os
import re
from moviepy.editor import VideoFileClip, AudioFileClip
from gtts import gTTS
from googletrans import Translator
from concurrent.futures import ThreadPoolExecutor
import time
import whisper_timestamped as whisper

def transcribe_audio(audio_path, transcript_path):
    try:
        audio = whisper.load_audio(audio_path)
        model = whisper.load_model("small")

        result = whisper.transcribe(model, audio, language="hi")

        # Write transcript to text file without timestamps
        with open(transcript_path, "w", encoding="utf-8") as txt_file:
            for segment in result['segments']:
                text = segment['text'].strip()
                txt_file.write(text + "\n")
                print(text)

        print("Transcription saved to:", transcript_path)
        return transcript_path
    except Exception as e:
        print(f"Error: {e}")
        return None

def translate_text(text, target_language):
    translator = Translator()
    translation = translator.translate(text, dest=target_language)
    return translation.text

def translate_paragraph(paragraph, target_language):
    translated_paragraph = ""
    chunks = [paragraph[i:i+500] for i in range(0, len(paragraph), 500)]

    def translate_chunk(chunk):
        return translate_text(chunk, target_language)

    with ThreadPoolExecutor(max_workers=4) as executor:
        translated_chunks = executor.map(translate_chunk, chunks)

    for translated_chunk in translated_chunks:
        translated_paragraph += translated_chunk

    return translated_paragraph

def save_to_file(translated_text, file_path):
    try:
        with open(file_path, 'w', encoding='utf-8') as file:
            file.write(translated_text.strip())
        print("Translated text saved to:", file_path)
    except Exception as e:
        print(f"Error occurred while saving to file: {e}")

def text_to_speech(translated_text, output_audio_path, target_language):
    tts = gTTS(text=translated_text, lang=target_language)
    tts.save(output_audio_path)
    print("Text-to-speech conversion saved to:", output_audio_path)
    return output_audio_path

def merge_audio_with_video(input_video_path, audio_path, output_video_path):
    video_clip = VideoFileClip(input_video_path)
    audio_clip = AudioFileClip(audio_path)

    duration_diff = video_clip.duration - audio_clip.duration
    if duration_diff > 0:
        speed_factor = audio_clip.duration / video_clip.duration
        audio_clip = audio_clip.speedx(speed_factor)
    elif duration_diff < 0:
        speed_factor = video_clip.duration / audio_clip.duration
        video_clip = video_clip.speedx(speed_factor)

    video_clip = video_clip.set_audio(audio_clip)
    video_clip.write_videofile(output_video_path, codec='libx264', audio_codec='aac')

    video_clip.close()
    audio_clip.close()

def main():
    audio_path = '/content/output_audio.mp3'  # Updated audio path
    transcript_path = "transcript_without_timestamps.txt"
    translated_text_path = "/content/india_translated.txt"
    target_language = input("Enter the target language code (e.g., 'fr' for French, 'es' for Spanish): ")
    input_video_path = "/content/video_without_audio.mp4"
    output_video_path = "/content/output_video_with_audio.mp4"
    output_audio_path = "temp_out.mp3"

    start_time = time.time()

    # Step 1: Transcribe audio
    transcript = transcribe_audio(audio_path, transcript_path)

    if transcript:
        with open(transcript, 'r', encoding='utf-8') as file:
            paragraph = file.read()
        print("Original Text:")
        print(paragraph)

        # Step 2: Translate text
        translated_paragraph = translate_paragraph(paragraph, target_language)
        if translated_paragraph:
            print("\nTranslated Text:")
            print(translated_paragraph)

            # Step 3: Save translated text
            save_to_file(translated_paragraph, translated_text_path)

            # Step 4: Text-to-Speech conversion
            tts_audio = text_to_speech(translated_paragraph, output_audio_path, target_language)

            # Step 5: Merge audio with video
            if os.path.exists(input_video_path) and os.path.exists(tts_audio):
                merge_audio_with_video(input_video_path, tts_audio, output_video_path)
                print("Video with merged audio saved successfully.")
            else:
                print("Input video or audio file not found.")
        else:
            print("Translation failed.")
    else:
        print("Text extraction failed.")

    end_time = time.time()
    print("Execution time:", end_time - start_time, "seconds")

if __name__ == "__main__":
    main()

"""**BERT SCORE ANALYSIS**"""

import subprocess
import tempfile
from googletrans import Translator
from bert_score import score
from sentence_transformers import SentenceTransformer, util
import nltk

# Download NLTK sentence tokenizer model if not already available
nltk.download('punkt')

# Initialize the translator and models
translator = Translator()
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Function to compute BERTScore for multiple sentences
def compute_bertscore(reference_sentences, candidate_sentences):
    P, R, F1 = score(candidate_sentences, reference_sentences, lang='en', verbose=True)
    return F1.mean().item()

# Function to compute sBERT similarity for multiple sentences
def compute_sbert(reference_sentences, candidate_sentences):
    reference_embeddings = model.encode(reference_sentences, convert_to_tensor=True)
    candidate_embeddings = model.encode(candidate_sentences, convert_to_tensor=True)
    similarities = util.cos_sim(reference_embeddings, candidate_embeddings).diag().tolist()
    return sum(similarities) / len(similarities) if similarities else 0

# Aggregate evaluation scores for the entire translation
def evaluate_translation(reference, candidate):
    print("Reference Text:")
    print(reference)
    print("\nTranslated Text:")
    print(candidate)

    # Use NLTK to split texts into sentences
    reference_sentences = nltk.sent_tokenize(reference)
    candidate_sentences = nltk.sent_tokenize(candidate)

    # Strip whitespace and filter out empty sentences
    reference_sentences = [sent.strip() for sent in reference_sentences if sent.strip()]
    candidate_sentences = [sent.strip() for sent in candidate_sentences if sent.strip()]

    print(f"Number of reference sentences: {len(reference_sentences)}")
    print(f"Number of candidate sentences: {len(candidate_sentences)}")

    # Ensure both lists have the same number of sentences
    if len(reference_sentences) != len(candidate_sentences):
        print(f"Warning: Different number of sentences ({len(reference_sentences)} vs {len(candidate_sentences)})")
        # Align sentences based on content similarity
        min_len = min(len(reference_sentences), len(candidate_sentences))
        reference_sentences = reference_sentences[:min_len]
        candidate_sentences = candidate_sentences[:min_len]
        print("Aligned sentences for evaluation.")

    # Evaluate with BERTScore
    bertscore_f1 = compute_bertscore(reference_sentences, candidate_sentences)
    print(f"\nAverage BERTScore F1: {bertscore_f1}")

    # Evaluate with sBERT similarity
    sbert_similarity = compute_sbert(reference_sentences, candidate_sentences)
    print(f"Average sBERT Similarity: {sbert_similarity}")

    return {
        "BERTScore_F1": bertscore_f1,
        "sBERT_Similarity": sbert_similarity
    }

# Example reference and candidate translations
reference_text = """
Hey everyone, welcome to another and already familiar to many of you speak English with me video and to our new filming spot. Well anyways, in this video you will practice your speaking with me. As usual we will have a dialogue where one line will be mine and the next one will be yours. I'm gonna say my line and then you will read your line from the screen out loud as if you were answering me and then vice versa. This is going to be a casual conversation between friends that are making plans. Apart from working on your speaking skills you might also pick up a phrase or two and improve your vocabulary. First you will listen to and watch the full dialogue and then we'll proceed to the practicing part. Okay, let's go. Hey Jenna, do you have any plans for this weekend? I don't think so. Why? My friend Angela is coming to town and I'd like to introduce you guys to each other. Remember I told you about her. Yes, I remember you talking about her. She sounds like a really nice person. I'd love to finally meet her in person. She and you have a lot in common. I'm sure you'll love her. Awesome. So what did you have in mind? Did you want to go somewhere? There's gonna be a fair on the King's Hill Farm. I was thinking we could go there on Saturday and then on Sunday to this new place on 45th. Lazy Bird? Yes, that one. I've been meaning to go check it out for a while. Yeah, me too. Perfect. Sounds like a plan. Looking forward to this weekend and meeting your friend. Hey Jenna, do you have any plans for this weekend? My friend Angela is coming to town and I'd like to introduce you guys to each other. Remember I told you about her. She and you have a lot in common. I'm sure you'll love her. There's gonna be a fair on the King's Hill Farm. I was thinking we could go there on Saturday and then on Sunday to this new place on 45th. Yes, that one. I've been meaning to go check it out for a while. Perfect. Okay, great job everyone. Now we switch. You go first. I don't think so. Why? Yes, I remember you talking about her. She sounds like a really nice person. I'd love to finally meet her in person. Awesome. So what did you have in mind? Did you want to go somewhere? Lazy Bird. Yeah, me too. Sounds like a plan. Looking forward to this weekend and meeting your friend. Okay, I hope you enjoyed practicing your speaking with me. If you like this format, please give this video a like, subscribe if you haven't yet, and I'll see you in the next one. Bye!
"""

# Replace 'candidate_text' with actual translation to be evaluated
candidate_text = """
みなさん、別の人へようこそ、すでに多くの人に馴染みのある私と私たちの新しい撮影スポットへの英語、とにかく、このビデオであなたは私と話すことを練習します、いつものように、私たちは対話をするでしょう、1つの行が私のもので、次の行はあなたのものです、私は自分のラインを言うつもりです、次に、あなたが答えているかのように大声で画面からあなたのラインを読みます、私、そしてその逆も同様です、これは友達の間のカジュアルな会話になるでしょう、それは計画を立てています、あなたのスピーキングスキルに取り組むことからフレーズを1つまたは2つ受け取り、語彙を改善します、最初に完全な対話を見てから、練習部分に進みます、わかった、さあ行こう、ねえジェナ、今週末の予定はありますか、私はそうは思わない、なぜ、私の友人のアンジェラが町に来ています、そして私はあなたたちを紹介したいです、お互い、私は彼女についてあなたに言ったことを忘れないでください、はい、私はあなたが彼女について話していることを覚えています、彼女は本当にいい人のように聞こえます、私は大好きですついに彼女に直接会うこと、彼女とあなたには多くの共通点があります、私はあなたが彼女を愛していると確信しています、素晴らしい、それで何をしましたか、どこかに行きたいですか、フェアがあります、キングスヒルファーム、私は土曜日にそこに行くことができると思っていました、45位のこの新しい場所への日曜日、怠けた鳥、はい、それは1つです、私は会ってきました、しばらくチェックしてください、ええ、私も、完璧、計画のように聞こえます、今週末を楽しみにして、あなたの友達に会います、さて、みんな素晴らしい仕事です、今、私たちは切り替えます、あなたは最初に行きます、私はそうは思わない、なぜ、はい、彼女について話しているのを覚えています、彼女は本当にいい人のように聞こえます、ついに彼女に直接会うのが大好きです、素晴らしい、それで、あなたは何を念頭に置いていましたか、どこかに行きたいですか、わかった、怠けた鳥、ええ、私も、計画のように聞こえます、今週末を楽しみにして、あなたの友達に会ってください、さて、私と一緒に話すことを練習するのを楽しんでいただければ幸いです、あなたがこれが好きなら、このビデオを同様にしてください、まだ行っていない場合は購読してください、次のものでお会いしましょう、さよなら!

"""

# Evaluate translation
evaluation_scores = evaluate_translation(reference_text, candidate_text)

# Display evaluation scores with descriptive messages
if evaluation_scores:
    print(f"\nAverage BERTScore F1 should be high. Obtained score: {evaluation_scores['BERTScore_F1']}")
    print(f"Average sBERT Similarity should be high. Obtained score: {evaluation_scores['sBERT_Similarity']}")
else:
    print("Evaluation could not be completed.")

"""**WER**"""

import string

def preprocess_text(text):
    # Convert text to lowercase
    text = text.lower()
    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    return text

def wer(reference, hypothesis):
    # Preprocess the reference and hypothesis
    ref_words = preprocess_text(reference).split()
    hyp_words = preprocess_text(hypothesis).split()

    # Check if the reference is empty to avoid division by zero
    if len(ref_words) == 0:
        return float('inf')  # Return infinity or some large value if reference is empty

    # Initialize the dynamic programming table
    dp = [[0] * (len(hyp_words) + 1) for _ in range(len(ref_words) + 1)]

    # Fill the dynamic programming table
    for i in range(len(ref_words) + 1):
        for j in range(len(hyp_words) + 1):
            if i == 0:
                dp[i][j] = j
            elif j == 0:
                dp[i][j] = i
            else:
                dp[i][j] = min(dp[i-1][j-1] + (0 if ref_words[i-1] == hyp_words[j-1] else 1),
                               dp[i-1][j] + 1,
                               dp[i][j-1] + 1)

    # Return the WER (normalized edit distance)
    return float(dp[len(ref_words)][len(hyp_words)]) / len(ref_words)

# Input the Youtube transcript (reference) and the Model transcript (hypothesis)
reference = """
किसी ने बड़े कमाल की बात कही है कि जीवन मिलना भाग्य की बात है, मृत्यु होना समय की बात है, और मृत्यु के बाद भी लोगों के दिलों में जीवित रहना कर्मों की बात है। नमस्ते दोस्तों, मैं हूं राज कार्तिक। एक डॉक्टर साहब अपने अस्पताल में दौड़े चले आ रहे थे, जितनी स्पीड में चल सकते थे, दौड़े चले आ रहे थे। ऑपरेशन थिएटर वाली लॉबी में आए तो उन्हें पांच-छह लोगों ने घेर लिया और सुनाने लगे कि अस्पताल खोल लिया है, अपने आप को क्या समझते हो, अब आ रहे हो, हम इतनी देर से इंतजार कर रहे हैं, आपको कोई सुध नहीं है, आपको कोई चिंता नहीं है, हमारा बच्चा ऑपरेशन थिएटर में है, हम इंतजार करते-करते थक गए, आप अब आ रहे हो। उन्होंने कहा, मुझे जान दीजिए, मुझे कम करना है। वो लोग सुनाने लगे कि डॉक्टर साहब, आपका बेटा होता तो क्या, आप इतने आराम से आते हैं, आप भाग के आते हैं, आप जल्दी आते हैं, आप ये करते हैं, वो करते हैं, बहुत कुछ कह दिया डॉक्टर साहब को। डॉक्टर साहब ने कोई रिएक्ट नहीं किया, वो दौड़ चले गए ऑपरेशन थिएटर में। एक डेढ़ घंटे तक ऑपरेशन चला। उसके बाद जब बाहर निकले तो फिर उन पांच-छह लोगों ने घेर लिया और पूछा कि क्या हुआ। डॉक्टर साहब ने कहा, बच्चा ठीक है, अब जल्द रिकवर करेगा। फिर उन्होंने सवाल किए कि कब डिस्चार्ज होगा, ये होगा। डॉक्टर साहब ने कहा, अब ये सारे सवाल आप नर्स से पूछ लीजिए, मुझे जान दीजिए। और फिर वो स्पीड से आए थे, उससे दोगुनी स्पीड से निकल गए। ये लोग समझने लगे कि डॉक्टर साहब कितने घमंडी हैं, बात तक करने की तमीज नहीं है। कुछ देर बाद नर्स ने बताया कि डॉक्टर साहब बहुत अच्छे हैं। आज सुबह एक रोड एक्सीडेंट में उनके बेटे की मौत हो गई थी, लेकिन वो बिना किसी देरी के दौड़े चले आए, ऑपरेशन थिएटर में गए, आपके बच्चे का ऑपरेशन किया, और अब उसे ठीक कर देंगे, चिंता मत कीजिए। डॉक्टर साहब शाम को अपने बेटे का अंतिम संस्कार करने जा रहे थे। इस कहानी का सार ये है कि बिना किसी की सिचुएशन समझे हम रिएक्ट कर देते हैं, हम स्थिति समझते नहीं हैं, बस अपनी बात थोप देते हैं और बाद में गिल्ट महसूस करने लगते हैं। इसलिए जीवन में कभी भी किसी की सिचुएशन जान बिना कोई भी टिप्पणी मत कीजिएगा। एक बार फिर से वही बात, जो अक्सर आपसे कहता हूं, अच्छा बनिए, बेहतर बनिए, बेहतरीन बनने का प्रयास कीजिए, जीवन में कर दिखाइए कुछ ऐसा कि दुनिया करना चाहे सिर्फ आपके जैसा। देखते रहिए हर सोमवार सुबह 9:30 बजे मेरे साथ एक नई मोटिवेशनल कहानी और हर शुक्रवार सुबह 9:30 बजे लर्निंग सीरीज का एक नया वीडियो।"""
hypothesis = """
किसी ने बड़े कमाल की बात कही है कि जीवन मिलना भाग्य की बात है, मृत्यु होना समय की बात है, और मृत्यु के बाद भी लोगों के दिलों में जीवित रहना कर्मों की बात है। नमस्ते दोस्तों, मैं हूँ आरजे कार्तिक। एक डॉक्टर अपने अस्पताल में दौड़े चले आ रहे थे, जितनी स्पीड में चल सकते थे, दौड़े चले आ रहे थे। ऑपरेशन थियेटर वाली लॉबी में आए तो पांच-छह लोगों ने घेर लिया और सुनाने लगे कि अस्पताल खोल लिया है, अपने आपको क्या समझते हो, अब आ रहे हो, हम इतनी देर से इंतजार कर रहे हैं, आपको कोई सुध नहीं है, आपको कोई चिंता नहीं है। उन लोगों ने डॉक्टर से कहा कि आपका बेटा होता तो क्या, आप इतने आराम से आते हैं, आप भाग के आते हैं, आप जल्दी आते हैं, आप ये करते हैं, वो करते हैं, बहुत कुछ कह दिया डॉक्टर साहब को। डॉक्टर साहब ने कोई प्रतिक्रिया नहीं की, वो दौड़ चले गए ऑपरेशन थियेटर में। एक डेढ़ घंटे तक ऑपरेशन चला। जब बाहर आए, तो पांच-छह लोगों ने फिर घेर लिया और पूछा कि क्या हुआ। डॉक्टर साहब ने कहा कि बच्चा ठीक है, अब जल्द रिकवर करेगा। उन्होंने सवाल किए कि कब डिस्चार्ज होगा, ये होगा। डॉक्टर साहब ने कहा कि अब ये सारे सवाल आप नर्स से पूछ लीजिए, मुझे जान दीजिए। फिर वो स्पीड से आए थे, उससे दोगुनी स्पीड से निकल गए। इन लोगों को लगा कि डॉक्टर कितने घमंडी हैं, बात तक करने की तमीज नहीं है। कुछ देर बाद नर्स आई और बताया कि डॉक्टर साहब बहुत अच्छे हैं, आज सुबह एक रोड एक्सीडेंट में उनके बेटे की मौत हो गई थी। लेकिन उन्होंने बिना किसी देरी के दौड़ कर आकर ऑपरेशन किया और अब बच्चे को ठीक कर देंगे। डॉक्टर शाम को अपने बेटे का अंतिम संस्कार करने जा रहे थे। इस कहानी का सार यह है कि बिना किसी की स्थिति समझे हम प्रतिक्रिया कर देते हैं और बाद में गिल्ट महसूस करने लगते हैं। इसलिए जीवन में कभी भी किसी की स्थिति जान बिना कोई टिप्पणी मत कीजिए। एक बार फिर से वही बात, जो अक्सर आपसे कहता हूं, अच्छा बनिए, बेहतर बनिए, बेहतरीन बनने का प्रयास कीजिए, जीवन में कर दिखाइए कुछ ऐसा कि दुनिया करना चाहे सिर्फ आपके जैसा। देखते रहिए हर सोमवार सुबह 9:30 बजे मेरे साथ एक नई मोटिवेशनल कहानी और हर शुक्रवार सुबह 9:30 बजे लर्निंग सीरीज का एक नया वीडियो।
"""

# Calculate the Word Error Rate (WER)
wer_score = wer(reference, hypothesis)
print("Word Error Rate:", wer_score)

"""**YOUTUBE TRANSCRIPT**"""

pip install youtube-transcript-api

import os
import re
import logging
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, VideoUnavailable, NoTranscriptFound

# Set up logging
logging.basicConfig(filename='transcript_scraper.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def extract_video_id(url):
    """
    Extract the video ID from a YouTube URL.
    """
    video_id = None
    pattern = r'(?:v=|\/)([0-9A-Za-z_-]{11}).*'
    match = re.search(pattern, url)
    if match:
        video_id = match.group(1)
    return video_id

def format_time(seconds):
    """
    Convert seconds to minutes and seconds format.
    """
    minutes = int(seconds // 60)
    seconds = seconds % 60
    return f"{minutes}:{seconds:05.2f}"

def get_transcript(video_id, language_code):
    try:
        # Fetch the transcript in the specified language
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[language_code])
        return transcript
    except NoTranscriptFound:
        logging.error(f"No transcript found for video ID {video_id} in language '{language_code}'.")
        return None
    except TranscriptsDisabled:
        logging.error(f"Transcripts are disabled for video ID {video_id}.")
        return None
    except VideoUnavailable:
        logging.error(f"Video is unavailable for video ID {video_id}.")
        return None
    except Exception as e:
        logging.error(f"An error occurred for video ID {video_id}: {e}")
        return None

def save_transcript(video_id, transcript, output_dir, language_code):
    # Ensure the output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Save the transcript with timestamps to a file
    file_path = os.path.join(output_dir, f"{video_id}_transcript_{language_code}.txt")
    with open(file_path, "w", encoding="utf-8") as f:
        for entry in transcript:
            if 'start' in entry and 'duration' in entry:
                start_time = format_time(entry['start'])
                end_time = format_time(entry['start'] + entry['duration'])
                f.write(f"{start_time} - {end_time} - {entry['text']}\n")
            else:
                logging.warning(f"Missing 'start' or 'duration' in transcript entry for video ID {video_id}.")
    print(f"Transcript saved as {file_path}")

def process_videos(url_list, output_dir, language_code):
    for url in url_list:
        video_id = extract_video_id(url)
        if video_id:
            transcript = get_transcript(video_id, language_code)
            if transcript:
                save_transcript(video_id, transcript, output_dir, language_code)
            else:
                logging.error(f"Failed to get transcript for video ID {video_id} in language '{language_code}'.")
        else:
            logging.error(f"Could not extract video ID from URL: {url}")

if __name__ == "__main__":
    # Allow user to input multiple YouTube URLs
    urls = []
    print("Enter YouTube URLs (type 'done' to finish):")

    while True:
        url = input("YouTube URL: ")
        if url.lower() == 'done':
            break
        urls.append(url)

    if urls:
        # Ask the user for the desired language code
        language_code = input("Enter the language code (e.g., 'es' for Spanish, 'fr' for French): ").strip()

        # Specify the directory where transcripts will be saved
        output_dir = "transcripts"
        process_videos(urls, output_dir, language_code)
    else:
        print("No URLs provided.")

"""**BACKUP CODE FOR JAPANESE ONLY**"""

import os
import re
from moviepy.editor import VideoFileClip, AudioFileClip
from gtts import gTTS
from googletrans import Translator
from concurrent.futures import ThreadPoolExecutor
import time
import whisper_timestamped as whisper

def transcribe_audio(audio_path, transcript_path):
    try:
        audio = whisper.load_audio(audio_path)
        model = whisper.load_model("small")

        result = whisper.transcribe(model, audio, language="it")

        with open(transcript_path, "w", encoding="utf-8") as txt_file:
            for segment in result['segments']:
                text = segment['text'].strip()
                txt_file.write(text + "\n")
                print(text)

        print("Transcription saved to:", transcript_path)
        return transcript_path
    except Exception as e:
        print(f"Error in transcription: {e}")
        return None

def translate_text(text, target_language):
    translator = Translator()
    try:
        translation = translator.translate(text, dest=target_language)
        if translation.text is None:
            raise ValueError("Translation returned None")
        return translation.text
    except Exception as e:
        print(f"Error in translation: {e}")
        return ""

def translate_paragraph(paragraph, target_language):
    translated_paragraph = ""
    chunks = [paragraph[i:i+500] for i in range(0, len(paragraph), 500)]

    def translate_chunk(chunk):
        result = translate_text(chunk, target_language)
        if result is None:
            result = ""  # Default to empty string if translation fails
        return result

    with ThreadPoolExecutor(max_workers=4) as executor:
        translated_chunks = executor.map(translate_chunk, chunks)

    for translated_chunk in translated_chunks:
        translated_paragraph += translated_chunk

    return translated_paragraph

def save_to_file(translated_text, file_path):
    try:
        with open(file_path, 'w', encoding='utf-8') as file:
            file.write(translated_text.strip())
        print("Translated text saved to:", file_path)
    except Exception as e:
        print(f"Error occurred while saving to file: {e}")

def text_to_speech(translated_text, output_audio_path, target_language):
    try:
        tts = gTTS(text=translated_text, lang=target_language)
        tts.save(output_audio_path)
        print("Text-to-speech conversion saved to:", output_audio_path)
        return output_audio_path
    except Exception as e:
        print(f"Error occurred in text-to-speech conversion: {e}")
        return None

def merge_audio_with_video(input_video_path, audio_path, output_video_path):
    try:
        video_clip = VideoFileClip(input_video_path)
        audio_clip = AudioFileClip(audio_path)

        duration_diff = video_clip.duration - audio_clip.duration
        if duration_diff > 0:
            speed_factor = audio_clip.duration / video_clip.duration
            audio_clip = audio_clip.speedx(speed_factor)
        elif duration_diff < 0:
            speed_factor = video_clip.duration / audio_clip.duration
            video_clip = video_clip.speedx(speed_factor)

        video_clip = video_clip.set_audio(audio_clip)
        video_clip.write_videofile(output_video_path, codec='libx264', audio_codec='aac')

        video_clip.close()
        audio_clip.close()
        print("Video with merged audio saved successfully.")
    except Exception as e:
        print(f"Error in merging audio with video: {e}")

def main():
    audio_path = '/content/output_audio.mp3'
    transcript_path = "transcript_without_timestamps.txt"
    translated_text_path = "/content/india_translated.txt"
    target_language = input("Enter the target language code (e.g., 'fr' for French, 'es' for Spanish): ")
    input_video_path = "/content/video_without_audio.mp4"
    output_video_path = "/content/output_video_with_audio.mp4"
    output_audio_path = "temp_out.mp3"

    start_time = time.time()

    transcript = transcribe_audio(audio_path, transcript_path)

    if transcript:
        try:
            with open(transcript, 'r', encoding='utf-8') as file:
                paragraph = file.read()
            print("Original Text:")
            print(paragraph)

            translated_paragraph = translate_paragraph(paragraph, target_language)
            if translated_paragraph:
                print("\nTranslated Text:")
                print(translated_paragraph)

                save_to_file(translated_paragraph, translated_text_path)

                tts_audio = text_to_speech(translated_paragraph, output_audio_path, target_language)

                if os.path.exists(input_video_path) and os.path.exists(tts_audio):
                    merge_audio_with_video(input_video_path, tts_audio, output_video_path)
                else:
                    print("Input video or audio file not found.")
            else:
                print("Translation failed.")
        except Exception as e:
            print(f"Error in processing the transcript: {e}")
    else:
        print("Text extraction failed.")

    end_time = time.time()
    print("Execution time:", end_time - start_time, "seconds")

if __name__ == "__main__":
    main()

